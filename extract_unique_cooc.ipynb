{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the disease\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import functions\n",
    "from functions import extract_data, count_notes_per_patient, logger, count_words_per_patient, find_frequent_word, find_cooc_per_patient\n",
    "from functions import cooc_log_odd_score, sequence2vec, other_emb\n",
    "from functions import create_graphs_lists, train_model, create_graph\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input vars --->\n",
    "disease_name = 'SEPSIS'\n",
    "database_path = '../MIMIC-III'\n",
    "inputs_path = os.path.join('data/inputs/', disease_name)\n",
    "\n",
    "patient_id_to_num_notes = {}\n",
    "\n",
    "number_of_patients = {}\n",
    "note_appearance_counter = {}\n",
    "## Step 4\n",
    "n_fold = float(3)\n",
    "threshold = float(0.01)\n",
    "frequent_word_lists = {}\n",
    "\n",
    "min_sup = 0.15\n",
    "# Input vars ---<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-22 16:04:26,106 - Number of patients in label_0: 260\n",
      "2021-01-22 16:04:26,108 - Number of patients in label_1: 842\n"
     ]
    }
   ],
   "source": [
    "alive_df = pd.read_csv(os.path.join(inputs_path,'alive_df.csv'))\n",
    "dead_df = pd.read_csv(os.path.join(inputs_path,'dead_df.csv'))\n",
    "\n",
    "logger.info(f\"Number of patients in label_0: {dead_df['SUBJECT_ID_x'].nunique()}\")\n",
    "logger.info(f\"Number of patients in label_1: {alive_df['SUBJECT_ID_x'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID_x</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>Probable atrial fibrillation. Downsloping ST s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "      <td>Sinus rhythm. First degree A-V block. Probable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94</td>\n",
       "      <td>[**2176-2-25**] 11:12 AM\\n CTA CHEST W&amp;W/O C &amp;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>[**2176-2-25**] 2:20 PM\\n CHEST (PORTABLE AP);...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94</td>\n",
       "      <td>[**2176-2-25**] 5:04 PM\\n CHEST PORT. LINE PLA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29131</th>\n",
       "      <td>99973</td>\n",
       "      <td>TITLE:\\n   Chief Complaint:\\n   24 Hour Events...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29132</th>\n",
       "      <td>99973</td>\n",
       "      <td>Chief Complaint:\\n   I saw and examined the pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29133</th>\n",
       "      <td>99973</td>\n",
       "      <td>This is a 65 yr woman with nka who was admitte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29134</th>\n",
       "      <td>99973</td>\n",
       "      <td>[**2180-11-29**] 3:43 PM\\n HIP UNILAT MIN 2 VI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29135</th>\n",
       "      <td>99973</td>\n",
       "      <td>[**Last Name (LF) **],[**First Name3 (LF) 4009...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29136 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SUBJECT_ID_x                                               TEXT\n",
       "0                94  Probable atrial fibrillation. Downsloping ST s...\n",
       "1                94  Sinus rhythm. First degree A-V block. Probable...\n",
       "2                94  [**2176-2-25**] 11:12 AM\\n CTA CHEST W&W/O C &...\n",
       "3                94  [**2176-2-25**] 2:20 PM\\n CHEST (PORTABLE AP);...\n",
       "4                94  [**2176-2-25**] 5:04 PM\\n CHEST PORT. LINE PLA...\n",
       "...             ...                                                ...\n",
       "29131         99973  TITLE:\\n   Chief Complaint:\\n   24 Hour Events...\n",
       "29132         99973  Chief Complaint:\\n   I saw and examined the pa...\n",
       "29133         99973  This is a 65 yr woman with nka who was admitte...\n",
       "29134         99973  [**2180-11-29**] 3:43 PM\\n HIP UNILAT MIN 2 VI...\n",
       "29135         99973  [**Last Name (LF) **],[**First Name3 (LF) 4009...\n",
       "\n",
       "[29136 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import text handling tool\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import csv\n",
    "import os.path\n",
    "\n",
    "# define constants\n",
    "# RESULT_HEADER = \"WORD, FREQUENCY\\n\"\n",
    "MIN_SEQ_LEN = 4\n",
    "USE_1_N_SEQ = 2\n",
    "\n",
    "\n",
    "# words that do not have meaning (can be modified later)\n",
    "USELESS_WORDS = [\"a\", \"the\", \"he\", \"she\", \",\", \".\", \"?\", \"!\", \":\", \";\", \"+\", \"*\", \"**\"\\\n",
    "                 \"your\", \"you\"]\n",
    "\n",
    "# count up the frequency of every word in every disease file\n",
    "stemmer = PorterStemmer()\n",
    "# create set of words to ignore in text\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for word in USELESS_WORDS:\n",
    "    stop_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID_x</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111</td>\n",
       "      <td>PATIENT/TEST INFORMATION:\\nIndication: s/p PEA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111</td>\n",
       "      <td>Compared to the previous tracing QRS voltage i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111</td>\n",
       "      <td>Normal sinus rhythm, rate 80.  Biatrial abnorm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111</td>\n",
       "      <td>Normal sinus rhythm.  Q waves in leads V1-V2 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111</td>\n",
       "      <td>Chief Complaint:  respiratory distress\\n   HPI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46129</th>\n",
       "      <td>99937</td>\n",
       "      <td>[**2128-5-11**] 11:57 AM\\n CHEST (PORTABLE AP)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46130</th>\n",
       "      <td>99937</td>\n",
       "      <td>[**2128-5-11**] 1:44 PM\\n CTA CHEST W&amp;W/O C&amp;RE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46131</th>\n",
       "      <td>99937</td>\n",
       "      <td>Normal sinus rhythm. Compared to tracing #1 no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46132</th>\n",
       "      <td>99937</td>\n",
       "      <td>[**2128-5-12**] 7:27 AM\\n CHEST (PORTABLE AP) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46133</th>\n",
       "      <td>99937</td>\n",
       "      <td>PATIENT/TEST INFORMATION:\\nIndication: Left ve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58029 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SUBJECT_ID_x                                               TEXT\n",
       "0               111  PATIENT/TEST INFORMATION:\\nIndication: s/p PEA...\n",
       "1               111  Compared to the previous tracing QRS voltage i...\n",
       "2               111  Normal sinus rhythm, rate 80.  Biatrial abnorm...\n",
       "3               111  Normal sinus rhythm.  Q waves in leads V1-V2 c...\n",
       "4               111  Chief Complaint:  respiratory distress\\n   HPI...\n",
       "...             ...                                                ...\n",
       "46129         99937  [**2128-5-11**] 11:57 AM\\n CHEST (PORTABLE AP)...\n",
       "46130         99937  [**2128-5-11**] 1:44 PM\\n CTA CHEST W&W/O C&RE...\n",
       "46131         99937  Normal sinus rhythm. Compared to tracing #1 no...\n",
       "46132         99937  [**2128-5-12**] 7:27 AM\\n CHEST (PORTABLE AP) ...\n",
       "46133         99937  PATIENT/TEST INFORMATION:\\nIndication: Left ve...\n",
       "\n",
       "[58029 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40684/40684 [04:36<00:00, 147.38it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "disease_df = pd.concat([dead_df, alive_df])\n",
    "stemmed_words_dict = {}\n",
    "for index, row in tqdm(disease_df.iterrows(), total=disease_df.shape[0]):\n",
    "    note = re.sub(r'\\[\\*\\*(.*?)\\*\\*\\]|[_,\\d\\*:~=\\.\\-\\+\\\\/]+', ' ', row['TEXT'])\n",
    "    tokenized_note = word_tokenize(note)\n",
    "    for word in tokenized_note:\n",
    "        stemmed_word = stemmer.stem(word.lower())\n",
    "        if not stemmed_word in stop_words:\n",
    "            if stemmed_word in all_words_set:\n",
    "                # Found a word. Put it into a dictionary\n",
    "\n",
    "                if stemmed_word in stemmed_words_dict:\n",
    "                    stemmed_word_set = stemmed_words_dict[stemmed_word][\"words\"]\n",
    "                    if word not in stemmed_word_set:\n",
    "                        stemmed_word_set.add(word.lower())\n",
    "                        notes_list = stemmed_words_dict[stemmed_word][\"notes\"]\n",
    "                        notes_list.append(row['TEXT'])\n",
    "                        stemmed_words_dict[stemmed_word] = {\"words\" : stemmed_word_set, \"notes\" : notes_list}\n",
    "                else:\n",
    "                    stemmed_words_dict[stemmed_word] = {\"words\" : {word.lower()}, \"notes\" : [row['TEXT']]}\n",
    "\n",
    "# https://stackoverflow.com/questions/7100125/storing-python-dictionaries\n",
    "# Write pickle file\n",
    "with open('stemmed_words_dict_SEPSIS.pickle', 'wb') as fp:\n",
    "    pickle.dump(stemmed_words_dict, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# Read pickle file\n",
    "# with open('data.pickle', 'rb') as fp:\n",
    "#     data = pickle.load(fp)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in stemmed_words_dict.items():\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stemmed_words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"PEA\"\n",
    "stemmed_word = 'pea'\n",
    "stemmed_words_dict[stemmed_word] = {\"words\" : word.lower()}\n",
    "print(stemmed_words_dict)\n",
    "print(stemmed_words_dict['pea']['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read json\n",
    "with open(os.path.join(inputs_path,'word_dict.json'), 'r') as fp:\n",
    "    word_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-22 16:05:07,186 - Get and normalize weights in co-occurrences...\n"
     ]
    }
   ],
   "source": [
    "# Read json\n",
    "with open(os.path.join(inputs_path,'patient_node_0.json'), 'r') as fp:\n",
    "    patient_node_0 = json.load(fp)\n",
    "with open(os.path.join(inputs_path,'patient_node_1.json'), 'r') as fp:\n",
    "    patient_node_1 = json.load(fp)\n",
    "# Read txt with tuples\n",
    "dic = ''\n",
    "with open(os.path.join(inputs_path,'patient_cooc_0.txt'),'r') as f:\n",
    "         for i in f.readlines():\n",
    "            dic=i #string\n",
    "patient_cooc_0 = eval(dic) # this is orignal dict with instace dict\n",
    "\n",
    "dic = ''\n",
    "with open(os.path.join(inputs_path,'patient_cooc_1.txt'),'r') as f:\n",
    "         for i in f.readlines():\n",
    "            dic=i #string\n",
    "patient_cooc_1 = eval(dic) # this is orignal dict with instace dict\n",
    "\n",
    "# Clean empty patients taht do not have any co-occurrences\n",
    "patient_cooc_0 = {k: v for k, v in patient_cooc_0.items() if bool(v)}\n",
    "patient_cooc_1 = {k: v for k, v in patient_cooc_1.items() if bool(v)}\n",
    "\n",
    "# Step 6\n",
    "logger.info(\"Get and normalize weights in co-occurrences...\")\n",
    "patient_cooc_set, normalized_cooc_odd_scores = cooc_log_odd_score(patient_cooc_0, patient_cooc_1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_cooc_odd_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_cooc_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load npy file\n",
    "sequence2vec = np.load(os.path.join(inputs_path,'sequence2vec.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence2vec[()]['NaN'] = np.zeros(128)\n",
    "sequence2vec[()]['NaN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_words_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(word_dict))\n",
    "print(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680\n"
     ]
    }
   ],
   "source": [
    "all_words_set = set()\n",
    "for item in patient_cooc_set:\n",
    "    all_words_set.add(item[0])\n",
    "    all_words_set.add(item[1])\n",
    "\n",
    "print(len(all_words_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, graph_labels, train_index, test_index = create_graphs_lists(patient_cooc_0, patient_cooc_1, normalized_cooc_odd_scores, sequence2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = graph_labels[1].value_counts()\n",
    "print(item_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graphs[52].__dict__)\n",
    "print()\n",
    "print(graphs[52].__dir__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs[52].edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_graph = graphs[52]\n",
    "print(tmp_graph.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tmp_graph.nodes():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graphs[52]._edge_weights('pea', 'arrest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(graphs[52].info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of patient's dictionaries\n",
    "patient_list_of_dicts = []\n",
    "for p in patient_cooc_0.items():\n",
    "    patient_list_of_dicts.append(p[1])\n",
    "    \n",
    "for p in patient_cooc_1.items():\n",
    "    patient_list_of_dicts.append(p[1])\n",
    "    \n",
    "len(patient_list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_graphs = copy.deepcopy(graphs)\n",
    "# tmp_graphs.pop()\n",
    "print(len(tmp_graphs))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in graphs:\n",
    "    print(p.nodes())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in all_words_set:\n",
    "    print(\"Word:\", word)\n",
    "    for p_idx, p_graph in enumerate(graphs):\n",
    "        # p_idx: num of a patient in a graphs list\n",
    "        # p_graph: graph of that patient\n",
    "        if word in p_graph.nodes():\n",
    "            print(p_idx)\n",
    "            patient_nan_dict = create_nan_patient(patient_list_of_dicts[p_idx], word)\n",
    "            patient_nan_graph = create_graph(patient_nan_dict,normalized_cooc_odd_scores, sequence2vec)\n",
    "            tmp_graphs[p_idx] = patient_nan_graph\n",
    "            break\n",
    "    break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graphs[467].edges())\n",
    "print()\n",
    "print(tmp_graphs[467].edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dict in a list and dict in a graph\n",
    "# They should be the same\n",
    "if pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_cooc = {('oob', 'stair'): 18.0, ('ctx', 'stair'): 18.0, ('ctx', 'oob'): 18.0, ('ambul', 'ctx'): 18.0, ('ambul', 'stair'): 18.0, ('ambul', 'oob'): 18.0, ('phenylephrin', 'video'): 15.0, ('barium', 'video'): 15.0}\n",
    "p_cooc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dict with NaN, instead of searched word\n",
    "# This dictionary then becomes an input to create a new graph\n",
    "\n",
    "def create_nan_patient(p_cooc, search_w):\n",
    "    new_dict = {}\n",
    "    for cooc in p_cooc:\n",
    "        if search_w in cooc[0]:\n",
    "            new_dict[('NaN', cooc[1])] = p_cooc[cooc]\n",
    "        elif search_w in cooc[1]:\n",
    "            new_dict[(cooc[0], 'NaN')] = p_cooc[cooc]\n",
    "        else:\n",
    "            new_dict[cooc] = p_cooc[cooc]\n",
    "    return new_dict\n",
    "\n",
    "# search_w = 'stair'\n",
    "# new_dict = {}\n",
    "# for cooc in p_cooc:\n",
    "#     if search_w in cooc[0]:\n",
    "#         new_dict[('NaN', cooc[1])] = p_cooc[cooc]\n",
    "#     elif search_w in cooc[1]:\n",
    "#         new_dict[(cooc[0], 'NaN')] = p_cooc[cooc]\n",
    "#     else:\n",
    "#         new_dict[cooc] = p_cooc[cooc]\n",
    "# new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_test_index = np.concatenate((train_index, test_index))\n",
    "new_test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "patient_idx_0 = [35]\n",
    "for idx in patient_idx_0:\n",
    "    for num, item in enumerate(patient_tmp_0):\n",
    "        if num == idx:\n",
    "            print(item, patient_tmp_0[item])\n",
    "            new_graph = create_graph(patient_tmp_0[item],normalized_cooc_odd_scores, sequence2vec)\n",
    "print(new_graph)\n",
    "print(new_graph.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "source = []\n",
    "target = []\n",
    "edge_weight = []\n",
    "node_idx = []\n",
    "cooc_odd_scores = normalized_cooc_odd_scores\n",
    "node_emb_dict = sequence2vec\n",
    "\n",
    "for cooc in patient_cooc_0[16684]:\n",
    "\n",
    "    source.extend([cooc[0], cooc[1]])\n",
    "    target.extend([cooc[1], cooc[0]])\n",
    "    edge_weight.extend([cooc_odd_scores[cooc], cooc_odd_scores[cooc]])\n",
    "        \n",
    "node_idx = list(set(source + target))\n",
    "\n",
    "print(node_idx)\n",
    "print(len(edge_weight))\n",
    "print(edge_weight)\n",
    "# Create a dataframe of only nodes\n",
    "square_node_data = pd.DataFrame(\n",
    "    index=node_idx)\n",
    "        \n",
    "# Create a dictionary for each column for a vector\n",
    "node_features = defaultdict(list)\n",
    "for node in node_idx:\n",
    "    # Case 1: Use in defaul embeddings training \n",
    "    # for i, vec in enumerate(node_emb_dict[node]):\n",
    "    # Case 2: Use when load npy file\n",
    "    for i, vec in enumerate(node_emb_dict[()][node]):\n",
    "        node_features['w_' + str(i)].append(vec)\n",
    "\n",
    "# Add columns to a dataframe\n",
    "for k, v in node_features.items():\n",
    "              \n",
    "    square_node_data[k] = v\n",
    "\n",
    "square_edges = pd.DataFrame({ \n",
    "    \"source\": source, \n",
    "    \"target\": target, \n",
    "    \"weight\":edge_weight\n",
    "})\n",
    "print(square_node_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "patient_tmp_0 = copy.deepcopy(patient_cooc_0)\n",
    "patient_tmp_1 = copy.deepcopy(patient_cooc_1)\n",
    "print(len(patient_tmp_0))\n",
    "print(len(patient_tmp_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Go through each patient and find if the patient has a word for which we are checking.\n",
    "If it does, mask the word as nan. \n",
    "- Add nan into emb_dict and set it is vector to zeros.\n",
    "- If there will be a co-occurrence with nan then set it's edge weigth to 0.5\n",
    "- Re-create graphs of these patients and check the accurracy\n",
    "\"\"\"\n",
    "\n",
    "# Find out if the word is in patients co-occurrences\n",
    "patient_idx_0 = []\n",
    "patient_idx_1 = []\n",
    "\n",
    "for word in all_words_set:\n",
    "    word = 'cmo'\n",
    "#     print(\"Word:\", word)\n",
    "#     print('='*60)\n",
    "    # Go through every patient\n",
    "    cnt_0 = 0\n",
    "    for k, v in patient_tmp_0.items():\n",
    "        # Go through every patient co-occurrence\n",
    "        for key, val in v.items():\n",
    "            if key[0] == word or key[1] == word:\n",
    "                print('-'*30)\n",
    "                print(\"Word:\", word)\n",
    "                print(f\"patient_tmp_0 -> key:{k}, cnt:{cnt_0}\")\n",
    "        cnt_0 += 1\n",
    "                break\n",
    "#     cnt_1 = 0\n",
    "#     for k, v in patient_tmp_1.items():\n",
    "#         if set_item in v:\n",
    "#             print('-'*30)\n",
    "#             print(f\"patient_tmp_1 -> key:{k}, cnt:{cnt_1}\")\n",
    "#             del v[set_item]\n",
    "#         cnt_1 += 1\n",
    "    break\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_item in patient_cooc_set:\n",
    "    set_item = ('declin', 'dic')\n",
    "    print('='*60)\n",
    "    print(\"Removing co-occurrence:\", set_item)\n",
    "    cnt_0 = 0\n",
    "    for k, v in patient_tmp_0.items():\n",
    "        if set_item in v:\n",
    "            print('-'*30)\n",
    "            print(f\"patient_tmp_0 -> key:{k}, cnt:{cnt_0}\")\n",
    "            del v[set_item]\n",
    "        cnt_0 += 1\n",
    "    cnt_1 = 0\n",
    "    for k, v in patient_tmp_1.items():\n",
    "        if set_item in v:\n",
    "            print('-'*30)\n",
    "            print(f\"patient_tmp_1 -> key:{k}, cnt:{cnt_1}\")\n",
    "            del v[set_item]\n",
    "        cnt_1 += 1\n",
    "            \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dead always start from 0\n",
    "start_index_alive = len(patient_cooc_0)\n",
    "print(\"Start index for alive:\", start_index_alive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load npy file\n",
    "sequence2vec = np.load(os.path.join(inputs_path,'sequence2vec.npy'), allow_pickle=True)\n",
    "# word2vec_emb = np.load(os.path.join(inputs_path,'word2vec_emb.npy'), allow_pickle=True)\n",
    "# fasttext_emb = np.load(os.path.join(inputs_path,'fasttext_emb.npy'), allow_pickle=True)\n",
    "# glove_emb = np.load(os.path.join(inputs_path,'glove_emb.npy'), allow_pickle=True)\n",
    "# sequence2vec_notWeighted = np.load(os.path.join(inputs_path,'sequence2vec_notWeighted.npy'), allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_tmp_0 = copy.deepcopy(patient_cooc_0)\n",
    "patient_tmp_1 = copy.deepcopy(patient_cooc_1)\n",
    "\n",
    "import time\n",
    "result_list = []\n",
    "for i_cnt, set_item in enumerate(patient_cooc_set):\n",
    "\n",
    "    # Read co-occurrences for dead patients\n",
    "    dic = ''\n",
    "    with open(os.path.join(inputs_path,'patient_cooc_0.txt'),'r') as f:\n",
    "            for i in f.readlines():\n",
    "                dic=i #string\n",
    "    patient_cooc_0 = eval(dic) # this is orignal dict with instace dict\n",
    "\n",
    "    # Read co-occurrences for alive patients\n",
    "    dic = ''\n",
    "    with open(os.path.join(inputs_path,'patient_cooc_1.txt'),'r') as f:\n",
    "            for i in f.readlines():\n",
    "                dic=i #string\n",
    "    patient_cooc_1 = eval(dic) # this is orignal dict with instace dict\n",
    "\n",
    "    # Count how many times set_item appears in each group\n",
    "    set_item_cnt_0 = 0\n",
    "    set_item_cnt_1 = 0\n",
    "    print('-' * 60)\n",
    "    print(\"Co-occurrence:\", set_item)\n",
    "    print(f\"Train model...iter: {i_cnt} out of {len(patient_cooc_set)}\")\n",
    "    \n",
    "    print(f\"Before patient_cooc_0:{sum_keys(patient_cooc_0)}, patient_cooc_1:{sum_keys(patient_cooc_1)}\")\n",
    "\n",
    "\n",
    "    for _, v in patient_cooc_0.items():\n",
    "        if set_item in v:\n",
    "            set_item_cnt_0 += 1\n",
    "            removed_items.append(set_item)\n",
    "            del v[set_item]\n",
    "\n",
    "    for _, v in patient_cooc_1.items():\n",
    "        if set_item in v:\n",
    "            set_item_cnt_1 += 1\n",
    "            removed_items.append(set_item)\n",
    "            del v[set_item]\n",
    "            \n",
    "    print(f\"set_item_cnt_0: {set_item_cnt_0}, set_item_cnt_1: {set_item_cnt_1}\")\n",
    "    print(f\"After patient_cooc_0:{sum_keys(patient_cooc_0)}, patient_cooc_1:{sum_keys(patient_cooc_1)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "logger.info(\"Create graphs, graph labels, train and test data...\")\n",
    "graphs, graph_labels, train_index, test_index = create_graphs_lists(patient_cooc_0, patient_cooc_1, normalized_cooc_odd_scores, sequence2vec)\n",
    "end = time.time()\n",
    "print(\"Running time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Train model...\")\n",
    "test_accs, test_f1_score, test_precision, test_recall, test_auc = train_model(graphs, graph_labels, train_index, test_index, \"seq2vec\", disease_name)\n",
    "logger.info(f\"Accuracy over all folds mean: {np.mean(test_accs)*100:.3}% and std: {np.std(test_accs)*100:.2}%\")\n",
    "logger.info(f\"F1_socre over all folds mean: {np.mean(test_f1_score)*100:.3}% and std: {np.std(test_f1_score)*100:.2}%\")\n",
    "logger.info(f\"Precision over all folds mean: {np.mean(test_precision)*100:.3}% and std: {np.std(test_precision)*100:.2}%\")\n",
    "logger.info(f\"Recall over all folds mean: {np.mean(test_recall)*100:.3}% and std: {np.std(test_recall)*100:.2}%\")\n",
    "logger.info(f\"AUC over all folds mean: {np.mean(test_auc)*100:.3}% and std: {np.std(test_auc)*100:.2}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sum_keys(d):\n",
    "    return 0 if not isinstance(d, dict) else len(d) + sum(sum_keys(v) for v in d.values())\n",
    "def removekey(d, key):\n",
    "    r = dict(d)\n",
    "    del r[key]\n",
    "    return r  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(patient_cooc_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_cooc_1[84858]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_all_cooc(patient_cooc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_keys(d):\n",
    "    return 0 if not isinstance(d, dict) else len(d) + sum(sum_keys(v) for v in d.values())\n",
    "print(f\"Before patient_cooc_0:{sum_keys(patient_cooc_0)}, patient_cooc_1:{sum_keys(patient_cooc_1)}\")\n",
    "\n",
    "logger.info(f\"Start the loop for set_item...{disease_name}\")\n",
    "\"\"\"\n",
    "Method to count change of accurracy depending on removing a co-occurrence\n",
    "\"\"\"\n",
    "result_list = []\n",
    "for i_cnt, set_item in enumerate(patient_cooc_set):\n",
    "\n",
    "    # Read co-occurrences for dead patients\n",
    "    dic = ''\n",
    "    with open(os.path.join(inputs_path,'patient_cooc_0.txt'),'r') as f:\n",
    "            for i in f.readlines():\n",
    "                dic=i #string\n",
    "    patient_cooc_0 = eval(dic) # this is orignal dict with instace dict\n",
    "\n",
    "    # Read co-occurrences for alive patients\n",
    "    dic = ''\n",
    "    with open(os.path.join(inputs_path,'patient_cooc_1.txt'),'r') as f:\n",
    "            for i in f.readlines():\n",
    "                dic=i #string\n",
    "    patient_cooc_1 = eval(dic) # this is orignal dict with instace dict\n",
    "\n",
    "    print('-' * 60)\n",
    "    print(f\"Before patient_cooc_0:{sum_keys(patient_cooc_0)}, patient_cooc_1:{sum_keys(patient_cooc_1)}\")\n",
    "    # Count how many times set_item appears in each group\n",
    "    set_item_cnt_0 = 0\n",
    "    set_item_cnt_1 = 0\n",
    "\n",
    "    for _, v in patient_cooc_0.items():\n",
    "        if set_item in v:\n",
    "            set_item_cnt_0 += 1\n",
    "            del v[set_item]\n",
    "\n",
    "    for _, v in patient_cooc_1.items():\n",
    "        if set_item in v:\n",
    "            set_item_cnt_1 += 1\n",
    "            del v[set_item]\n",
    "\n",
    "    \n",
    "    print(\"Co-occurrence:\", set_item)\n",
    "    logger.info(\"Create graphs, graph labels, train and test data...\")\n",
    "    graphs, graph_labels, train_index, test_index = create_graphs_lists(patient_cooc_0, patient_cooc_1, normalized_cooc_odd_scores, sequence2vec)\n",
    "    new_test_index = np.concatenate((train_index, test_index))\n",
    "    print(f\"Train model...iter: {i_cnt} out of {len(patient_cooc_set)}\")\n",
    "    test_accs, test_f1_score, test_precision, test_recall, test_auc = train_model(graphs, graph_labels, train_index, new_test_index, \"seq2vec\", disease_name)\n",
    "\n",
    "    accs = np.mean(test_accs)*100\n",
    "    accs_std = np.std(test_accs)*100\n",
    "    f1_score = np.mean(test_f1_score)*100\n",
    "    f1_score_std = np.std(test_f1_score)*100\n",
    "    precision = np.mean(test_precision)*100\n",
    "    precision_std = np.std(test_precision)*100\n",
    "    recall = np.mean(test_recall)*100\n",
    "    recall_std = np.std(test_recall)*100\n",
    "    auc = np.mean(test_auc)*100\n",
    "    auc_std = np.std(test_auc)*100\n",
    "\n",
    "\n",
    "    print(f\"set_item_cnt_0: {set_item_cnt_0}, set_item_cnt_1: {set_item_cnt_1}\")\n",
    "    print(f\"After patient_cooc_0:{sum_keys(patient_cooc_0)}, patient_cooc_1:{sum_keys(patient_cooc_1)}\")\n",
    "    # print(f\"test_accs: {accs} accs_std: {accs_std}, test_f1_score: {f1_score} f1_score_std: {f1_score_std}, test_precision: {precision} precision_std: {precision_std}, test_recall: {recall} recall_std: {recall_std}, test_auc: {auc} auc_std: {auc_std}\")\n",
    "    print(f\"test_accs: {accs}, test_f1_score: {f1_score}, test_precision: {precision}, test_recall: {recall}, test_auc: {auc}\")\n",
    "    result_list.append([set_item, set_item_cnt_0, set_item_cnt_1, accs, f1_score, precision, recall, auc])\n",
    "\n",
    "with open(os.path.join(inputs_path,'remove_cooc_result_list.json'), 'w') as fp:\n",
    "    json.dump(result_list, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put together remove_cooc_result_list and stemmed_words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the disease\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import functions\n",
    "from functions import extract_data, count_notes_per_patient, logger, count_words_per_patient, find_frequent_word, find_cooc_per_patient\n",
    "from functions import cooc_log_odd_score, sequence2vec, other_emb\n",
    "from functions import create_graphs_lists, train_model, create_graph\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_name = 'PNEUMONIA'\n",
    "database_path = '../MIMIC-III'\n",
    "inputs_path = os.path.join('data/inputs/', disease_name)\n",
    "\n",
    "import pickle\n",
    "# Read pickle file\n",
    "file_name = \"stemmed_words_dict_PNEUMONIA.pickle\"\n",
    "with open(os.path.join(inputs_path, file_name), 'rb') as fp:\n",
    "    stemmed_words_dict = pickle.load(fp)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stemmed_words_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in stemmed_words_dict.items():\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words_df = pd.DataFrame(stemmed_words_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pea</th>\n",
       "      <th>arrest</th>\n",
       "      <th>precordium</th>\n",
       "      <th>cpr</th>\n",
       "      <th>norepinephrin</th>\n",
       "      <th>paralyt</th>\n",
       "      <th>phenylephrin</th>\n",
       "      <th>vasopressin</th>\n",
       "      <th>bicarbon</th>\n",
       "      <th>pcv</th>\n",
       "      <th>...</th>\n",
       "      <th>passi</th>\n",
       "      <th>muir</th>\n",
       "      <th>knowledg</th>\n",
       "      <th>passey</th>\n",
       "      <th>autoset</th>\n",
       "      <th>spacer</th>\n",
       "      <th>xanax</th>\n",
       "      <th>klonopin</th>\n",
       "      <th>ciwa</th>\n",
       "      <th>coach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <td>{pea, peas}</td>\n",
       "      <td>{arrest, arrested, arrests}</td>\n",
       "      <td>{precordium}</td>\n",
       "      <td>{cpr}</td>\n",
       "      <td>{norepinephrin, norepinephrine}</td>\n",
       "      <td>{paralytic, paralytics}</td>\n",
       "      <td>{phenylephrine}</td>\n",
       "      <td>{vasopressin}</td>\n",
       "      <td>{bicarbonate}</td>\n",
       "      <td>{pcv}</td>\n",
       "      <td>...</td>\n",
       "      <td>{passie, passy}</td>\n",
       "      <td>{muir, muire}</td>\n",
       "      <td>{knowledgeable, knowledge}</td>\n",
       "      <td>{passey}</td>\n",
       "      <td>{autoset}</td>\n",
       "      <td>{spacer}</td>\n",
       "      <td>{xanax}</td>\n",
       "      <td>{klonopin, klonopins}</td>\n",
       "      <td>{ciwa, ciwas}</td>\n",
       "      <td>{coaching, coach, coached}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>notes</th>\n",
       "      <td>[PATIENT/TEST INFORMATION:\\nIndication: s/p PE...</td>\n",
       "      <td>[PATIENT/TEST INFORMATION:\\nIndication: s/p PE...</td>\n",
       "      <td>[Compared to the previous tracing QRS voltage ...</td>\n",
       "      <td>[Chief Complaint:  respiratory distress\\n   HP...</td>\n",
       "      <td>[Chief Complaint:  respiratory distress\\n   HP...</td>\n",
       "      <td>[Chief Complaint:  respiratory distress\\n   HP...</td>\n",
       "      <td>[Chief Complaint:  respiratory distress\\n   HP...</td>\n",
       "      <td>[Chief Complaint:  respiratory distress\\n   HP...</td>\n",
       "      <td>[Chief Complaint:  respiratory distress\\n   HP...</td>\n",
       "      <td>[Chief Complaint:  respiratory distress\\n   HP...</td>\n",
       "      <td>...</td>\n",
       "      <td>[85 y/o M with respiratory failure [**3-5**] t...</td>\n",
       "      <td>[Pneumonia, bacterial, ventilator acquired (VA...</td>\n",
       "      <td>[Respiratory failure, acute (not ARDS/[**Docto...</td>\n",
       "      <td>[Respiratory failure, acute (not ARDS/[**Docto...</td>\n",
       "      <td>[Demographics\\n   Day of intubation:\\n   Day o...</td>\n",
       "      <td>[CCU Nursing Progress Note (MICU service) 0700...</td>\n",
       "      <td>[NURSING PROGRESS NOTE 0400-0700\\nREPORT RECEI...</td>\n",
       "      <td>[NPN 7a-7P:\\n     REview of systems;\\n    Nuer...</td>\n",
       "      <td>[[**Hospital Unit Name **] nsg note: 7:00-19:0...</td>\n",
       "      <td>[M/SICU NURSING PROGRESS NOTE.\\n     SEE CAREV...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 607 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     pea  \\\n",
       "words                                        {pea, peas}   \n",
       "notes  [PATIENT/TEST INFORMATION:\\nIndication: s/p PE...   \n",
       "\n",
       "                                                  arrest  \\\n",
       "words                        {arrest, arrested, arrests}   \n",
       "notes  [PATIENT/TEST INFORMATION:\\nIndication: s/p PE...   \n",
       "\n",
       "                                              precordium  \\\n",
       "words                                       {precordium}   \n",
       "notes  [Compared to the previous tracing QRS voltage ...   \n",
       "\n",
       "                                                     cpr  \\\n",
       "words                                              {cpr}   \n",
       "notes  [Chief Complaint:  respiratory distress\\n   HP...   \n",
       "\n",
       "                                           norepinephrin  \\\n",
       "words                    {norepinephrin, norepinephrine}   \n",
       "notes  [Chief Complaint:  respiratory distress\\n   HP...   \n",
       "\n",
       "                                                 paralyt  \\\n",
       "words                            {paralytic, paralytics}   \n",
       "notes  [Chief Complaint:  respiratory distress\\n   HP...   \n",
       "\n",
       "                                            phenylephrin  \\\n",
       "words                                    {phenylephrine}   \n",
       "notes  [Chief Complaint:  respiratory distress\\n   HP...   \n",
       "\n",
       "                                             vasopressin  \\\n",
       "words                                      {vasopressin}   \n",
       "notes  [Chief Complaint:  respiratory distress\\n   HP...   \n",
       "\n",
       "                                                bicarbon  \\\n",
       "words                                      {bicarbonate}   \n",
       "notes  [Chief Complaint:  respiratory distress\\n   HP...   \n",
       "\n",
       "                                                     pcv  ...  \\\n",
       "words                                              {pcv}  ...   \n",
       "notes  [Chief Complaint:  respiratory distress\\n   HP...  ...   \n",
       "\n",
       "                                                   passi  \\\n",
       "words                                    {passie, passy}   \n",
       "notes  [85 y/o M with respiratory failure [**3-5**] t...   \n",
       "\n",
       "                                                    muir  \\\n",
       "words                                      {muir, muire}   \n",
       "notes  [Pneumonia, bacterial, ventilator acquired (VA...   \n",
       "\n",
       "                                                knowledg  \\\n",
       "words                         {knowledgeable, knowledge}   \n",
       "notes  [Respiratory failure, acute (not ARDS/[**Docto...   \n",
       "\n",
       "                                                  passey  \\\n",
       "words                                           {passey}   \n",
       "notes  [Respiratory failure, acute (not ARDS/[**Docto...   \n",
       "\n",
       "                                                 autoset  \\\n",
       "words                                          {autoset}   \n",
       "notes  [Demographics\\n   Day of intubation:\\n   Day o...   \n",
       "\n",
       "                                                  spacer  \\\n",
       "words                                           {spacer}   \n",
       "notes  [CCU Nursing Progress Note (MICU service) 0700...   \n",
       "\n",
       "                                                   xanax  \\\n",
       "words                                            {xanax}   \n",
       "notes  [NURSING PROGRESS NOTE 0400-0700\\nREPORT RECEI...   \n",
       "\n",
       "                                                klonopin  \\\n",
       "words                              {klonopin, klonopins}   \n",
       "notes  [NPN 7a-7P:\\n     REview of systems;\\n    Nuer...   \n",
       "\n",
       "                                                    ciwa  \\\n",
       "words                                      {ciwa, ciwas}   \n",
       "notes  [[**Hospital Unit Name **] nsg note: 7:00-19:0...   \n",
       "\n",
       "                                                   coach  \n",
       "words                         {coaching, coach, coached}  \n",
       "notes  [M/SICU NURSING PROGRESS NOTE.\\n     SEE CAREV...  \n",
       "\n",
       "[2 rows x 607 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_words_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(inputs_path,'remove_cooc_result_list.json'), 'r') as fp:\n",
    "    remove_cooc_result_list = json.load(fp)\n",
    "len(remove_cooc_result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['forth',\n",
       "  0,\n",
       "  1,\n",
       "  91.89189076423645,\n",
       "  83.56708288192749,\n",
       "  83.04682970046997,\n",
       "  86.38889193534851,\n",
       "  95.20286321640015]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_cooc_result_list[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['word', 'num_of_patients_0', 'num_of_patients_1', 'accs', 'f1_score', 'precision', 'recall', 'auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pandas DataFrame \n",
    "remove_cooc_result_df = pd.DataFrame(remove_cooc_result_list, columns = columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>num_of_patients_0</th>\n",
       "      <th>num_of_patients_1</th>\n",
       "      <th>accs</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forth</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91.891891</td>\n",
       "      <td>83.567083</td>\n",
       "      <td>83.046830</td>\n",
       "      <td>86.388892</td>\n",
       "      <td>95.202863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cocain</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>90.315318</td>\n",
       "      <td>82.766289</td>\n",
       "      <td>83.046830</td>\n",
       "      <td>84.833336</td>\n",
       "      <td>93.916863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ggo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91.891891</td>\n",
       "      <td>83.567083</td>\n",
       "      <td>83.046830</td>\n",
       "      <td>86.388892</td>\n",
       "      <td>95.206696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>diamox</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91.891891</td>\n",
       "      <td>83.567083</td>\n",
       "      <td>83.046830</td>\n",
       "      <td>86.388892</td>\n",
       "      <td>95.200318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hugger</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>91.666669</td>\n",
       "      <td>83.388782</td>\n",
       "      <td>83.042079</td>\n",
       "      <td>86.038470</td>\n",
       "      <td>94.969475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>treitz</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>91.779280</td>\n",
       "      <td>83.510590</td>\n",
       "      <td>83.046830</td>\n",
       "      <td>86.277783</td>\n",
       "      <td>95.132726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>captopril</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>89.977479</td>\n",
       "      <td>82.570648</td>\n",
       "      <td>83.036953</td>\n",
       "      <td>84.465808</td>\n",
       "      <td>93.366325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>adenosin</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>91.666669</td>\n",
       "      <td>83.454096</td>\n",
       "      <td>83.046830</td>\n",
       "      <td>86.166674</td>\n",
       "      <td>95.073205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>thrive</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>91.666669</td>\n",
       "      <td>83.441174</td>\n",
       "      <td>83.074605</td>\n",
       "      <td>86.055565</td>\n",
       "      <td>95.163333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>sxn'ing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91.891891</td>\n",
       "      <td>83.567083</td>\n",
       "      <td>83.046830</td>\n",
       "      <td>86.388892</td>\n",
       "      <td>95.192242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>607 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  num_of_patients_0  num_of_patients_1       accs   f1_score  \\\n",
       "0        forth                  0                  1  91.891891  83.567083   \n",
       "1       cocain                  0                 15  90.315318  82.766289   \n",
       "2          ggo                  0                  1  91.891891  83.567083   \n",
       "3       diamox                  0                  1  91.891891  83.567083   \n",
       "4       hugger                  8                  5  91.666669  83.388782   \n",
       "..         ...                ...                ...        ...        ...   \n",
       "602     treitz                  1                  2  91.779280  83.510590   \n",
       "603  captopril                  1                 19  89.977479  82.570648   \n",
       "604   adenosin                  0                  3  91.666669  83.454096   \n",
       "605     thrive                  2                  4  91.666669  83.441174   \n",
       "606    sxn'ing                  0                  1  91.891891  83.567083   \n",
       "\n",
       "     precision     recall        auc  \n",
       "0    83.046830  86.388892  95.202863  \n",
       "1    83.046830  84.833336  93.916863  \n",
       "2    83.046830  86.388892  95.206696  \n",
       "3    83.046830  86.388892  95.200318  \n",
       "4    83.042079  86.038470  94.969475  \n",
       "..         ...        ...        ...  \n",
       "602  83.046830  86.277783  95.132726  \n",
       "603  83.036953  84.465808  93.366325  \n",
       "604  83.046830  86.166674  95.073205  \n",
       "605  83.074605  86.055565  95.163333  \n",
       "606  83.046830  86.388892  95.192242  \n",
       "\n",
       "[607 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_cooc_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "# copy.deepcopy(patient_cooc_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "607it [00:00, 13165.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Create a combined list\n",
    "for num, item in tqdm(enumerate(remove_cooc_result_list)):\n",
    "    stemmed_words = str(stemmed_words_dict[remove_cooc_result_list[num][0]]['words'])\n",
    "    stemmed_words_notes = str(stemmed_words_dict[remove_cooc_result_list[num][0]]['notes'][:2])\n",
    "    item.append(stemmed_words)\n",
    "    item.append(stemmed_words_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['forth',\n",
       " 0,\n",
       " 1,\n",
       " 91.89189076423645,\n",
       " 83.56708288192749,\n",
       " 83.04682970046997,\n",
       " 86.38889193534851,\n",
       " 95.20286321640015,\n",
       " \"{'forth', 'forthe'}\",\n",
       " '[\"NPN 0700-1900\\\\n\\\\n68yo female w/metastatic NSCLC stage 4B with metastatic brain lesions s/p craniotomy 3 weeks ago, presented with fever, rigors, dyspnea, and cough; found to have large R sided post obstructive pna.\\\\n\\\\nNeuro: Sedated on fentanyl/versed 25/1; opens eyes and follows commands occasionally, also seemed agitated at times, moving head back and forth and pulling on restraints; given fentanyl boluses prn. Maintenance dose not increased d/t hemodynamic instability. No seizure activity, remains on phenytoin, level this am subtherapeutic at 8.1\\\\n\\\\nCV: ABP 76-124/45-72, given 1L fluid bolus for low CVP and uo; levo weaned off in am but turned back on for ABP in the 70\\'s; also started on vasopressin per Dr. [**Last Name (STitle) **] w/ plan to wean levo then keep vasopressin for 24hrs after levo off. HR 67-99, SR no ectopy, rate has decreased progressively; CVP 5-9; Transfused 1 unit PRBC\\'s for crit 24. Post transfusion crit pending. Generalized body edema present [**3-15**]+, [**Month/Day (3) **] >LLE from DVT being treated with lovenox.\\\\n\\\\nResp: Intubated on PCV mode 20/peep16/rate16/fiO2 65%; TV\\'s in high 400\\'s and 500\\'s, spontaneous resps [**6-19**]. O2 sats 92-97%; Lung sounds are coarse throughout; CXR showed improvement from yesterday; suctioned occasionally for moderate amts thin white sputum. Esophageal balloon placed for determining optimal level of peep.\\\\n\\\\nGI/FEN: Abdomen soft, ND, NT, hypoactive BS, no stools; TF started this afternoon, replete w/fiber at 10/hr; K of 3.4 repleted with 60meq IV.\\\\n\\\\nGU: Foley draining 10-90cc/hr; low uo of 10cc/hr treated w/ fluid bolus of 1L NS; plan is to give 500cc bolus for uo <30cc/hr; creatinine wnl; fluid status is +9L in 48hrs.\\\\n\\\\nID: Tmax 98.6; vanco held this am for trough of 30, zosyn decreased for renal concerns, continues on azithromycin.\\\\n\\\\nEndo: FS 107-127, no insulin coverage given.\\\\n\\\\nSocial: Husband and daughter in today, updated by resident.\\\\n\\\\nPlan: Monitor hemodynamic status, continue vasopressin for 24hrs after levo weaned; fluid boluses for low CVP and UO.\\\\nMonitor resp status, wean settings as tolerated, suction prn.\\\\nMonitor temp, wbc\\'s, follow cultures.\\\\nMonitor fluid/electrolyte status, replete lytes prn.\\\\nFSBG qid, RISS.\\\\n\", \\'NURSING PROGRESS NOTES 1900-0700\\\\nPT VERY AGITATED DISTRACTION, MOVING POSITION TO CHAIR, REORIENTATION NOT RELIEVING SEVERE AGITATION. PT C/O BACK PAIN. PT SITTING UP IN BED LEANING FROM SIDE TO SIDE. TLCL PULLING WHEN PT LEANS BACK AND FORTH 1:1 SITTER AT BEDSIDE. TLCL AT RISK TO BE PULLED OUT W/ FREQUENT THRASHING.  AMITRIPTYLINE 25MG GIVEN AT HS AND ANOTHER 25MG [** 3195**] GIVEN W/ NO RELIEF. GEODAN 10MG IM GIVEN W/ NO RELIEF. PT PLACED IN LEATHER RESTRAINTS FOR SAFETY.  PT CONT TO C/O BACK PAIN. MS 5MG IVP GIVEN X 2 5MIN APART W/ WONDERFUL RELIEF OF BACK PAIN AND AGITATION. PT RESTING COMFORTABLY, SLEEPING. HE IS ABLE TO WAKE UP BRIEFLY AND HAVE SHORT CONVERSATIONS.\\\\n\\\\nNEURO: PT NOW SLEEPING AND WAKES UP FOR BRIEF PERIODS BUT ABLE TO GO BACK TO SLEEP ON HIS OWN. MAE. 1:1 SITTER REMAINS AT BEDSIDE FOR SAFETY.\\\\n\\\\nRESP: PT PLACED BACK ON AEROSOL FACE TENT 50% SATS 95-97% RR 20S. LS CLEAR W/ DIMINISHED BASES. PT HAS A STRONG NONPRODUCTIVE COUGH.\\\\n\\\\nCV: WHEN AGITATED AND C/O BACK PAIN HRT RATE 130S. NOW PT NSR 80S BP WNL. HRT SOUNDS S1S2. PEDAL PULSES +3. LABS DRAWN THIS AM K+3.7 MG 1.8\\\\nAWAITING MD ORDERS FOR REPLACEMENT.\\\\n\\\\nGI: ABD SOFT BS+ NO STOOL THIS SHIFT. NGT INTACT. PT REMAINS NPO, ? SWALLOW EVAL TODAY. TPN INFUSING FOR NUTRITION.\\\\n\\\\nGU: FOLEY CATH DRAINING YELLOW URINE 50-450CC/HR.\\\\n\\\\nENDO: INSULIN GTT SHUT OFF AT 2100 FOR BS 51 D50 [**1-5**] AMP IV GIVEN. INSULIN GTT RESTARTED AT 0300 FOR BS 200. NOW AT 3UNITS/HR\\\\n\\\\nID: PT ON [**Name (NI) 10370**]/ OXACILLIN\\\\n\\\\nCOMFORT: PT ON SEROQUEL, ZYPREXA, TRAZADONE @ HS [**Name (NI) 3195**], AMITRIPTYLINE HS AND HS [**Name (NI) 3195**] ADDITIONAL DOSE. FENTANYL 150MEQ/HR AND VERSED 2MG/HR. WILL NEED TO DECREASE FENTANYL TO 100MEQ/HR AT 0800 THIS AM. [**Month (only) 108**] NEED TO ADD MS IV AS [**Month (only) 3195**] DOSE FOR BACK PAIN ( HE USED TO WORK FOR MOVING COMPANY).\\\\n\\\\nSOCIAL: MOTHER IS CONTACT PERSON NO CONTACT LAST EVENING.\\\\n\\\\nCODE: FULL\\\\n\\\\nPLAN:\\\\nCONT TO WEAN FENTANYL TO 100MEQ/HR @0800.\\\\n[**Month (only) 108**] NEED TO ADD MS [**First Name (Titles) **] [**Last Name (Titles) 3195**] FOR BACK PAIN.\\\\n? SWALLOW EVAL\\\\n? CHANGING INSULIN TO SQ AND FINGER STICK Q 4HRS.\\\\n? INCREASING AMITRIPTYLINE TO 75MG AS AT HOME FOR HIS RESTLESS LEG SYNDROME.\\\\nREPLACE LYTES\\\\nCONT 1:1  AND RESTRAIN AS NEEDED\\\\n\\']']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_cooc_result_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['word', 'num_of_patients_0', 'num_of_patients_1', 'accs', 'f1_score', 'precision', 'recall', 'auc', 'references_for_stemmed_word', 'notes_with_stemmed_word']\n",
    "# Create the pandas DataFrame of stemmed words and texts for each word\n",
    "combined_df = pd.DataFrame(remove_cooc_result_list, columns = columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>num_of_patients_0</th>\n",
       "      <th>num_of_patients_1</th>\n",
       "      <th>accs</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "      <th>references_for_stemmed_word</th>\n",
       "      <th>notes_with_stemmed_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>treitz</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>91.779280</td>\n",
       "      <td>83.510590</td>\n",
       "      <td>83.046830</td>\n",
       "      <td>86.277783</td>\n",
       "      <td>95.132726</td>\n",
       "      <td>{'treitz'}</td>\n",
       "      <td>[\"[**2144-5-9**] 3:23 PM\\n N-G TUBE PLACEMENT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>captopril</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>89.977479</td>\n",
       "      <td>82.570648</td>\n",
       "      <td>83.036953</td>\n",
       "      <td>84.465808</td>\n",
       "      <td>93.366325</td>\n",
       "      <td>{'captopril', 'captoprile'}</td>\n",
       "      <td>['MICU A Nursing Progress Note (0700-1900)\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>adenosin</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>91.666669</td>\n",
       "      <td>83.454096</td>\n",
       "      <td>83.046830</td>\n",
       "      <td>86.166674</td>\n",
       "      <td>95.073205</td>\n",
       "      <td>{'adenosine'}</td>\n",
       "      <td>[\"PMICU Nursing Progress Note 7a-7p\\n\\n Pt and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>thrive</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>91.666669</td>\n",
       "      <td>83.441174</td>\n",
       "      <td>83.074605</td>\n",
       "      <td>86.055565</td>\n",
       "      <td>95.163333</td>\n",
       "      <td>{'thrive'}</td>\n",
       "      <td>[\"[**2123-7-6**] 3:57 PM\\n CT CHEST W/CONTRAST...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>sxn'ing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>91.891891</td>\n",
       "      <td>83.567083</td>\n",
       "      <td>83.046830</td>\n",
       "      <td>86.388892</td>\n",
       "      <td>95.192242</td>\n",
       "      <td>{\"sxn'ing\"}</td>\n",
       "      <td>[\"Nursing progress note (7pm-7am):\\n\\nEvents: ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  num_of_patients_0  num_of_patients_1       accs   f1_score  \\\n",
       "602     treitz                  1                  2  91.779280  83.510590   \n",
       "603  captopril                  1                 19  89.977479  82.570648   \n",
       "604   adenosin                  0                  3  91.666669  83.454096   \n",
       "605     thrive                  2                  4  91.666669  83.441174   \n",
       "606    sxn'ing                  0                  1  91.891891  83.567083   \n",
       "\n",
       "     precision     recall        auc  references_for_stemmed_word  \\\n",
       "602  83.046830  86.277783  95.132726                   {'treitz'}   \n",
       "603  83.036953  84.465808  93.366325  {'captopril', 'captoprile'}   \n",
       "604  83.046830  86.166674  95.073205                {'adenosine'}   \n",
       "605  83.074605  86.055565  95.163333                   {'thrive'}   \n",
       "606  83.046830  86.388892  95.192242                  {\"sxn'ing\"}   \n",
       "\n",
       "                               notes_with_stemmed_word  \n",
       "602  [\"[**2144-5-9**] 3:23 PM\\n N-G TUBE PLACEMENT ...  \n",
       "603  ['MICU A Nursing Progress Note (0700-1900)\\n\\n...  \n",
       "604  [\"PMICU Nursing Progress Note 7a-7p\\n\\n Pt and...  \n",
       "605  [\"[**2123-7-6**] 3:57 PM\\n CT CHEST W/CONTRAST...  \n",
       "606  [\"Nursing progress note (7pm-7am):\\n\\nEvents: ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv (r'remove_one_word_PNEUMONIA.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
